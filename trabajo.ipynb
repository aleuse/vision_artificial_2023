{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo VisiÃ³n Artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.10\n",
      "  Using cached tensorflow_gpu-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/97/43/4cd9dc8c051537ed0613fcfc4229dfb9eb39fe058c8d42632977465bfdb5/numpy-1.26.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.0-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.1 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.1/61.1 kB 820.0 kB/s eta 0:00:00\n",
      "Collecting matplotlib\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/01/50/0d8d8f044e2a0d8151e9ed59fe50924e9e697ba43a8b12d5ff9b45adb871/matplotlib-3.8.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading matplotlib-3.8.0-cp39-cp39-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting pillow\n",
      "  Obtaining dependency information for pillow from https://files.pythonhosted.org/packages/a8/fd/ce5fab4a15f4e38c5f6b86377f2c2ef6c92ec9a48e7296048251057a58ec/Pillow-10.0.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading Pillow-10.0.1-cp39-cp39-win_amd64.whl.metadata (9.6 kB)\n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/e9/20/2d0561ab54d857365926c5b53538369a7b8d6ccbffaca509305b074028cd/scipy-1.11.2-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached scipy-1.11.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/fb/c4/f574ba6f04e6d7bf8c38d23e7a52389566dd7631fee0bcdd79ea07ef2dbf/opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-gpu==2.10)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for flatbuffers>=2.0 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-gpu==2.10)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-gpu==2.10)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/a0/62/9790f98aa125a035cda91be7a41a46bdc76b26ffdd2ad2d3c5b7f7232946/h5py-3.9.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached h5py-3.9.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow-gpu==2.10)\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-gpu==2.10)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from tensorflow-gpu==2.10) (23.1)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow-gpu==2.10)\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from tensorflow-gpu==2.10) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from tensorflow-gpu==2.10) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu==2.10)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from tensorflow-gpu==2.10) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-gpu==2.10)\n",
      "  Using cached wrapt-1.15.0-cp39-cp39-win_amd64.whl (36 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-gpu==2.10)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/f3/b5/f4c2f0495007a955953d88119c428e4b14868caba2db585382e34074075f/grpcio-1.58.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.58.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorboard<2.11,>=2.10 (from tensorflow-gpu==2.10)\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow-gpu==2.10)\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow-gpu==2.10)\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/87/2b/9b49451f7412cc1a79198e94a771a4e52d65c479aae610b1161c0290ef2c/contourpy-1.1.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Downloading contourpy-1.1.1-cp39-cp39-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/1b/6d/93121de94919bd072a93131167d7c6244eb26fe9f2f897ddfee8eb550ffa/fonttools-4.42.1-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached fonttools-4.42.1-cp39-cp39-win_amd64.whl.metadata (154 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/ca/c1/1f986c8119c0c57c2bd71d1941da23332c38ee2c90117e46dff4358b70f7/kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Obtaining dependency information for importlib-resources>=3.2.0 from https://files.pythonhosted.org/packages/65/6e/09d8816b5cb7a4006ef8ad1717a2703ad9f331dae9717d9f22488a2d6469/importlib_resources-6.1.0-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.10) (0.41.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/23/e4/abbb8763fdf6279c471443251b3f847ee9a172d1776742b266fe6de7ac86/google_auth-2.23.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/1a/b5/228c1cdcfe138f1a8e01ab1b54284c8b83735476cb22b6ba251656ed13ad/Markdown-3.4.4-py3-none-any.whl.metadata\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for requests<3,>=2.21.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/9b/59/a7c32e3d8d0e546a206e0552a2c04444544f15c1da4a01df8938d20c6ffc/werkzeug-2.3.7-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-2.3.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3>=2.0.5 (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for urllib3>=2.0.5 from https://files.pythonhosted.org/packages/37/dc/399e63f5d1d96bb643404ee830657f4dfcf8503f5ba8fa3c6d465d0c57fe/urllib3-2.0.5-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\anaconda3\\envs\\visionartificial\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10) (6.8.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/cb/dd/dce14328e6abe0f475e606131298b4c8f628abd62a4e6f27fdfa496b9efe/charset_normalizer-3.2.0-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached charset_normalizer-3.2.0-cp39-cp39-win_amd64.whl.metadata (31 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Obtaining dependency information for MarkupSafe>=2.1.1 from https://files.pythonhosted.org/packages/a2/b2/624042cb58cc6b3529a6c3a7b7d230766e3ecb768cba118ba7befd18ed6f/MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading numpy-1.26.0-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/15.8 MB 1.8 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.3/15.8 MB 2.0 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.3/15.8 MB 1.8 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/15.8 MB 2.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.7/15.8 MB 2.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/15.8 MB 2.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.0/15.8 MB 2.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.2/15.8 MB 3.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.5/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.7/15.8 MB 3.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.6/15.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.9/15.8 MB 4.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.3/15.8 MB 4.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.6/15.8 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.0/15.8 MB 4.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.9/15.8 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.3/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.7/15.8 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.2/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.7/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.2/15.8 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.7/15.8 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.2/15.8 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.9/15.8 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 11.0/15.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.8 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.7/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.2/15.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.8/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.8.0-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/7.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.0/7.6 MB 10.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.6/7.6 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.1/7.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.7/7.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.2/7.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.8/7.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.3/7.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.9/7.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.4/7.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.9/7.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.5/7.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.6/7.6 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading Pillow-10.0.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.6/2.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.1/2.5 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.7/2.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.2/2.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 10.7 MB/s eta 0:00:00\n",
      "Using cached scipy-1.11.2-cp39-cp39-win_amd64.whl (44.1 MB)\n",
      "Using cached opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.2/130.2 kB ? eta 0:00:00\n",
      "Downloading contourpy-1.1.1-cp39-cp39-win_amd64.whl (435 kB)\n",
      "   ---------------------------------------- 0.0/436.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 436.0/436.0 kB 13.7 MB/s eta 0:00:00\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached fonttools-4.42.1-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Downloading grpcio-1.58.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 15.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.0/4.3 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.3 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.1/4.3 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.7/4.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.2/4.3 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.8/4.3 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached h5py-3.9.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 103.1/103.1 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.23.1-py2.py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 181.9/181.9 kB 11.4 MB/s eta 0:00:00\n",
      "Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Using cached charset_normalizer-3.2.0-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Using cached MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
      "   ---------------------------------------- 0.0/123.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 123.8/123.8 kB 7.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, keras, flatbuffers, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyparsing, pyasn1, protobuf, pillow, oauthlib, numpy, MarkupSafe, kiwisolver, importlib-resources, idna, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, astunparse, absl-py, werkzeug, scipy, rsa, requests, pyasn1-modules, opt-einsum, opencv-python, markdown, keras-preprocessing, h5py, contourpy, requests-oauthlib, matplotlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-gpu\n",
      "Successfully installed MarkupSafe-2.1.3 absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 certifi-2023.7.22 charset-normalizer-3.2.0 contourpy-1.1.1 cycler-0.11.0 flatbuffers-23.5.26 fonttools-4.42.1 gast-0.4.0 google-auth-2.23.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.58.0 h5py-3.9.0 idna-3.4 importlib-resources-6.1.0 keras-2.10.0 keras-preprocessing-1.1.2 kiwisolver-1.4.5 libclang-16.0.6 markdown-3.4.4 matplotlib-3.8.0 numpy-1.26.0 oauthlib-3.2.2 opencv-python-4.8.0.76 opt-einsum-3.3.0 pillow-10.0.1 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 pyparsing-3.1.1 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.11.2 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.10.0 tensorflow-gpu-2.10.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 urllib3-2.0.5 werkzeug-2.3.7 wrapt-1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow-gpu==2.10 numpy matplotlib pillow scipy opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImportaciÃ³n de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU fÃ­sica(s), 1 GPU(s) lÃ³gica(s)\n"
     ]
    }
   ],
   "source": [
    "# Configura la asignaciÃ³n de memoria GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Limita la asignaciÃ³n de memoria a 1 GB\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    "        )\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"GPU fÃ­sica(s),\", len(logical_gpus), \"GPU(s) lÃ³gica(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajando con el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def distribuir_imagenes(carpeta_imagenes, carpetas_destino, proporciones, semilla = None):\n",
    "    \"\"\"\n",
    "    Distribuye copias aleatorias de imÃ¡genes desde una carpeta de origen a varias carpetas de destino\n",
    "    segÃºn las proporciones especificadas.\n",
    "\n",
    "    Args:\n",
    "        carpeta_imagenes (str): Ruta de la carpeta que contiene las imÃ¡genes.\n",
    "        carpetas_destino (list of str): Lista de rutas de las carpetas de destino.\n",
    "        proporciones (list of int): Lista de proporciones para cada carpeta de destino en porcentaje.\n",
    "        semilla (int): Semilla para el generador de nÃºmeros aleatorios (opcional).\n",
    "    \"\"\"\n",
    "    if sum(proporciones) != 100:\n",
    "        raise ValueError(\"Las proporciones deben sumar 100.\")\n",
    "\n",
    "    if semilla is not None:\n",
    "        random.seed(semilla)\n",
    "\n",
    "    archivos = os.listdir(carpeta_imagenes)\n",
    "    total_archivos = 8000\n",
    "\n",
    "    for i, carpeta_destino in enumerate(carpetas_destino):\n",
    "        cantidad_archivos = total_archivos * proporciones[i] // 100\n",
    "\n",
    "        # Crear la carpeta de destino si no existe\n",
    "        os.makedirs(carpeta_destino, exist_ok=True)\n",
    "\n",
    "        for _ in range(cantidad_archivos):\n",
    "            archivo = random.choice(archivos)\n",
    "            origen = os.path.join(carpeta_imagenes, archivo)\n",
    "            destino = os.path.join(carpeta_destino, archivo)\n",
    "            shutil.copy(origen, destino)\n",
    "\n",
    "    print(\"DistribuciÃ³n de copias de imÃ¡genes completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistribuciÃ³n de copias de imÃ¡genes completada.\n"
     ]
    }
   ],
   "source": [
    "carpeta_imagenes = r\"Healthy\"\n",
    "carpetas_destino = [r\"dataset\\train\\healthy\", r\"dataset\\test\\healthy\", r\"dataset\\validation\\healthy\"]\n",
    "proporciones = [80, 10, 10]\n",
    "semilla = 42\n",
    "distribuir_imagenes(carpeta_imagenes, carpetas_destino, proporciones, semilla = semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistribuciÃ³n de copias de imÃ¡genes completada.\n"
     ]
    }
   ],
   "source": [
    "carpeta_imagenes = r\"Leaf rust\"\n",
    "carpetas_destino = [r\"dataset\\train\\leaf_rust\", r\"dataset\\test\\leaf_rust\", r\"dataset\\validation\\leaf_rust\"]\n",
    "proporciones = [80, 10, 10]\n",
    "semilla = 42\n",
    "distribuir_imagenes(carpeta_imagenes, carpetas_destino, proporciones, semilla = semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file dataset\\test\\leaf_rust\\2 (2).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\3 (1).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\3 (19).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\3 (36).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (10).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (17).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (25).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (29).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (33).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (39).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (40).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (46).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (47).jpeg  has an invalid extension jpeg\n",
      "file dataset\\test\\leaf_rust\\5 (58).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\healthy\\2 (691).jpg is not a valid image file \n",
      "file dataset\\train\\leaf_rust\\1 (1).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\1 (3).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\1 (5).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\1 (6).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\1 (7).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\1 (9).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\2 (15).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\2 (16).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\2 (18).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\2 (4).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\2 (7).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (1).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (10).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (11).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (12).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (13).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (14).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (15).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (17).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (18).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (21).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (25).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (28).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (3).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (31).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (32).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (34).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (36).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\3 (8).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\45ee85b23568.jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (1).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (11).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (12).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (14).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (15).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (16).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (18).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (20).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (22).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (25).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (26).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (27).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (28).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (3).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (30).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (32).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (33).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (34).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (35).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (38).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (4).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (41).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (42).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (43).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (48).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (5).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (50).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (51).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (54).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (55).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (56).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (57).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (59).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (60).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (61).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (63).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (64).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (66).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (67).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (68).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (69).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (7).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (70).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (71).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5 (8).jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\5bebb67939fe.jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\807020c32d10.jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\ac35fbede402.jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\bdd8518099d8.jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\c36737d752cf.jpeg  has an invalid extension jpeg\n",
      "file dataset\\train\\leaf_rust\\cc315fcca9ff.jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\1 (7).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\2 (16).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\2 (8).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\3 (16).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\3 (35).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\3 (4).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\3 (6).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\3 (8).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\5 (15).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\5 (45).jpeg  has an invalid extension jpeg\n",
      "file dataset\\validation\\leaf_rust\\5 (6).jpeg  has an invalid extension jpeg\n",
      "['dataset\\\\test\\\\leaf_rust\\\\2 (2).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\3 (1).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\3 (19).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\3 (36).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (10).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (17).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (25).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (29).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (33).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (39).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (40).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (46).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (47).jpeg', 'dataset\\\\test\\\\leaf_rust\\\\5 (58).jpeg', 'dataset\\\\train\\\\healthy\\\\2 (691).jpg', 'dataset\\\\train\\\\leaf_rust\\\\1 (1).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\1 (3).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\1 (5).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\1 (6).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\1 (7).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\1 (9).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\2 (15).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\2 (16).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\2 (18).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\2 (4).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\2 (7).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (1).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (10).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (11).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (12).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (13).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (14).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (15).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (17).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (18).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (21).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (25).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (28).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (3).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (31).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (32).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (34).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (36).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\3 (8).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\45ee85b23568.jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (1).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (11).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (12).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (14).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (15).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (16).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (18).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (20).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (22).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (25).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (26).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (27).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (28).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (3).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (30).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (32).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (33).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (34).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (35).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (38).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (4).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (41).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (42).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (43).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (48).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (5).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (50).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (51).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (54).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (55).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (56).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (57).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (59).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (60).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (61).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (63).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (64).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (66).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (67).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (68).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (69).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (7).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (70).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (71).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5 (8).jpeg', 'dataset\\\\train\\\\leaf_rust\\\\5bebb67939fe.jpeg', 'dataset\\\\train\\\\leaf_rust\\\\807020c32d10.jpeg', 'dataset\\\\train\\\\leaf_rust\\\\ac35fbede402.jpeg', 'dataset\\\\train\\\\leaf_rust\\\\bdd8518099d8.jpeg', 'dataset\\\\train\\\\leaf_rust\\\\c36737d752cf.jpeg', 'dataset\\\\train\\\\leaf_rust\\\\cc315fcca9ff.jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\1 (7).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\2 (16).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\2 (8).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\3 (16).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\3 (35).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\3 (4).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\3 (6).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\3 (8).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\5 (15).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\5 (45).jpeg', 'dataset\\\\validation\\\\leaf_rust\\\\5 (6).jpeg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "bad_list=[]\n",
    "dir=r'dataset'\n",
    "subdir_list=os.listdir(dir) # create a list of the sub directories in the directory ie train or test\n",
    "for d in subdir_list:  # iterate through the sub directories train and test\n",
    "    dpath=os.path.join (dir, d) # create path to sub directory\n",
    "    if d in ['test', 'train', \"validation\"]:\n",
    "        class_list=os.listdir(dpath) # list of classes ie dog or cat\n",
    "       # print (class_list)\n",
    "        for klass in class_list: # iterate through the two classes\n",
    "            class_path=os.path.join(dpath, klass) # path to class directory\n",
    "            #print(class_path)\n",
    "            file_list=os.listdir(class_path) # create list of files in class directory\n",
    "            for f in file_list: # iterate through the files\n",
    "                fpath=os.path.join (class_path,f)\n",
    "                index=f.rfind('.') # find index of period infilename\n",
    "                ext=f[index+1:] # get the files extension\n",
    "                if ext  not in ['jpg', 'png', 'bmp', 'gif']:\n",
    "                    print(f'file {fpath}  has an invalid extension {ext}')\n",
    "                    bad_list.append(fpath)                    \n",
    "                else:\n",
    "                    try:\n",
    "                        img=cv2.imread(fpath)\n",
    "                        size=img.shape\n",
    "                    except:\n",
    "                        print(f'file {fpath} is not a valid image file ')\n",
    "                        bad_list.append(fpath)\n",
    "                       \n",
    "print (bad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bad_list:\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de ImÃ¡genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un generador de imÃ¡genes para Training\n",
    "trainImgGen = ImageDataGenerator(\n",
    "    # Escalar los valores de las imÃ¡genes para que vayan entre 0 y 1\n",
    "    rescale = 1. / 255,\n",
    "    # RotaciÃ³n de 40Â°\n",
    "    rotation_range = 31,\n",
    "    # Movimiento horizontal\n",
    "    width_shift_range = 0.6,\n",
    "    # Movimiento vertical\n",
    "    height_shift_range = 0.35,\n",
    "    # Cortar\n",
    "    shear_range = 0.2,\n",
    "    # Zoom\n",
    "    zoom_range = 0.2,\n",
    "    # RotaciÃ³n horizontal\n",
    "    horizontal_flip = True,\n",
    "    # RotaciÃ³n vertical\n",
    "    vertical_flip = True,\n",
    "    # Rellenar los espacios vacÃ­os de la imagen al momento de transformarla\n",
    "    fill_mode = \"nearest\",\n",
    "    # Cambiar el brillo\n",
    "    brightness_range = [0.4, 1.5]\n",
    ")\n",
    "\n",
    "# Creamos un generador de imÃ¡genes para Test y Validation simplemente escalando los valores para que vayan de 0 a 1\n",
    "testDataGen = ImageDataGenerator(rescale = 1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9832 images belonging to 2 classes.\n",
      "Found 1529 images belonging to 2 classes.\n",
      "Found 1546 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generamos imÃ¡genes para training cargÃ¡ndolas de un directorio\n",
    "trainGenerator = trainImgGen.flow_from_directory(r\"dataset/train\",\n",
    "    # TamaÃ±o de las imÃ¡genes\n",
    "    target_size = (128, 128),\n",
    "    # Paquetes de a 64 imÃ¡genes\n",
    "    batch_size = 64,\n",
    "    # ClasificaciÃ³n binaria\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "\n",
    "# Generamos imÃ¡genes para validation cargÃ¡ndolas de un directorio y solamente reescalÃ¡ndolas\n",
    "validationGenerator = testDataGen.flow_from_directory(r\"dataset/validation\",\n",
    "    # TamaÃ±o de las imÃ¡genes\n",
    "    target_size = (128, 128),\n",
    "    # Paquetes de a 64 imÃ¡genes\n",
    "    batch_size = 64,\n",
    "    # ClasificaciÃ³n binaria\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "\n",
    "# Generamos imÃ¡genes para testing cargÃ¡ndolas de un directorio y solamente reescalÃ¡ndolas\n",
    "testGenerator = testDataGen.flow_from_directory(r\"dataset/test\",\n",
    "    # TamaÃ±o de las imÃ¡genes\n",
    "    target_size = (128, 128),\n",
    "    # Paquetes de a 64 imÃ¡genes\n",
    "    batch_size = 64,\n",
    "    # ClasificaciÃ³n binaria\n",
    "    class_mode = \"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CreaciÃ³n de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    # Nombre del archivo. La extensiÃ³n hdf5 es usada para guardar los pesos del modelo\n",
    "    filepath = f\"visionArtificial{str(datetime.date.today())}.hdf5\",\n",
    "    verbose = 1,\n",
    "    # MÃ©trica que queremos monitorear\n",
    "    monitor = \"val_accuracy\",\n",
    "    # Solo guardar los mejores pesos\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n de la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128, 128, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,437,569\n",
      "Trainable params: 4,436,865\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creamos un modelo secuencial\n",
    "model = Sequential()\n",
    "\n",
    "\"\"\"\n",
    "Capa de entrada\n",
    "\"\"\"\n",
    "# Agregamos una capa de convoluciÃ³n\n",
    "model.add(Conv2D(\n",
    "        # 32 kernels\n",
    "        filters = 32, \n",
    "        # Kernels de 3x3\n",
    "        kernel_size = (3, 3),\n",
    "        # Agregamos un padding para que las imÃ¡genes despuÃ©s del kernel tengan el mismo tamaÃ±o que las de entrada\n",
    "        padding = \"same\",\n",
    "        # FunciÃ³n de activaciÃ³n ReLu\n",
    "        activation = \"relu\",\n",
    "        # Utilizamos regularizaciÃ³n Ridge con peso de 1e-5\n",
    "        kernel_regularizer = regularizers.l2(1e-5),\n",
    "        # Datos de entrada de 128 pixeles con 3 canales\n",
    "        input_shape = (128, 128, 3)\n",
    "    )\n",
    ")\n",
    "# Apilamos una capa de Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Apilamos una capa de MaxPooling para eliminar ruido de tamaÃ±o 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\"\"\"\n",
    "Capa de convoluciÃ³n 2\n",
    "\"\"\"\n",
    "# Agregamos una capa de convoluciÃ³n\n",
    "model.add(Conv2D(\n",
    "        # 64 kernels\n",
    "        filters = 64, \n",
    "        # Kernels de 3x3\n",
    "        kernel_size = (3, 3),\n",
    "        # Agregamos un padding para que las imÃ¡genes despuÃ©s del kernel tengan el mismo tamaÃ±o que las de entrada\n",
    "        padding = \"same\",\n",
    "        # FunciÃ³n de activaciÃ³n ReLu\n",
    "        activation = \"relu\",\n",
    "        # Utilizamos regularizaciÃ³n Ridge con peso de 1e-5\n",
    "        kernel_regularizer = regularizers.l2(1e-5),\n",
    "    )\n",
    ")\n",
    "# Apilamos una capa de Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Apilamos una capa de MaxPooling para eliminar ruido de tamaÃ±o 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Agregamos una capa de Dropout para vigilar el Overfitting; la probabilidad de drop serÃ¡ de 0.2\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\"\"\"\n",
    "Capa de convoluciÃ³n 3\n",
    "\"\"\"\n",
    "# Agregamos una capa de convoluciÃ³n\n",
    "model.add(Conv2D(\n",
    "        # 128 kernels\n",
    "        filters = 128, \n",
    "        # Kernels de 3x3\n",
    "        kernel_size = (3, 3),\n",
    "        # Agregamos un padding para que las imÃ¡genes despuÃ©s del kernel tengan el mismo tamaÃ±o que las de entrada\n",
    "        padding = \"same\",\n",
    "        # FunciÃ³n de activaciÃ³n ReLu\n",
    "        activation = \"relu\",\n",
    "        # Utilizamos regularizaciÃ³n Ridge con peso de 1e-5\n",
    "        kernel_regularizer = regularizers.l2(1e-5),\n",
    "    )\n",
    ")\n",
    "# Apilamos una capa de Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Apilamos una capa de MaxPooling para eliminar ruido de tamaÃ±o 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Agregamos una capa de Dropout para vigilar el Overfitting; la probabilidad de drop serÃ¡ de 0.3\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\"\"\"\n",
    "Capa de convoluciÃ³n 4\n",
    "\"\"\"\n",
    "# Agregamos una capa de convoluciÃ³n\n",
    "model.add(Conv2D(\n",
    "        # 128 kernels\n",
    "        filters = 128, \n",
    "        # Kernels de 3x3\n",
    "        kernel_size = (3, 3),\n",
    "        # Agregamos un padding para que las imÃ¡genes despuÃ©s del kernel tengan el mismo tamaÃ±o que las de entrada\n",
    "        padding = \"same\",\n",
    "        # FunciÃ³n de activaciÃ³n ReLu\n",
    "        activation = \"relu\",\n",
    "        # Utilizamos regularizaciÃ³n Ridge con peso de 1e-5\n",
    "        kernel_regularizer = regularizers.l2(1e-5),\n",
    "    )\n",
    ")\n",
    "# Apilamos una capa de Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Apilamos una capa de MaxPooling para eliminar ruido de tamaÃ±o 2x2\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Agregamos una capa de Dropout para vigilar el Overfitting; la probabilidad de drop serÃ¡ de 0.4\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "\"\"\"\n",
    "Capa de salida\n",
    "\"\"\"\n",
    "# Agregamos una capa Flatten para aplanar los datos y que queden en una sola dimensiÃ³n\n",
    "model.add(Flatten())\n",
    "# Agregamos una capa de Dropout para vigilar el Overfitting; la probabilidad de drop serÃ¡ de 0.5\n",
    "model.add(Dropout(0.5))\n",
    "# Agregamos una capa Densa con 512 neuronas y activaciÃ³n ReLu\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "# Agregamos la capa encargada de la clasificaciÃ³n binaria con activaciÃ³n sigmoide\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CompilaciÃ³n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # FunciÃ³n de pÃ©rdida binary Cross Entropy\n",
    "    loss = 'binary_crossentropy',\n",
    "    # Como optimizador utilizamos Adam que combina las bondades de AdaGrad y RMSProp\n",
    "    optimizer = optimizers.Adam(),\n",
    "    # Como mÃ©trica utilizamos el Accuracy Score\n",
    "    metrics = \"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to visionArtificial2023-09-26.hdf5\n",
      "154/154 - 35s - loss: 0.0933 - accuracy: 0.9879 - val_loss: 0.0378 - val_accuracy: 1.0000 - 35s/epoch - 230ms/step\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0027 - val_accuracy: 1.0000 - 27s/epoch - 176ms/step\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0552 - accuracy: 0.9941 - val_loss: 0.1437 - val_accuracy: 0.9588 - 27s/epoch - 173ms/step\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "154/154 - 28s - loss: 0.0283 - accuracy: 0.9950 - val_loss: 0.0052 - val_accuracy: 1.0000 - 28s/epoch - 181ms/step\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "154/154 - 29s - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.0029 - val_accuracy: 1.0000 - 29s/epoch - 188ms/step\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 177ms/step\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.0074 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0029 - val_accuracy: 1.0000 - 26s/epoch - 172ms/step\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 177ms/step\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 175ms/step\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 172ms/step\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0029 - val_accuracy: 1.0000 - 26s/epoch - 172ms/step\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 175ms/step\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 176ms/step\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 1.0000 - 27s/epoch - 172ms/step\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 175ms/step\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0029 - val_accuracy: 1.0000 - 26s/epoch - 170ms/step\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0029 - val_accuracy: 1.0000 - 26s/epoch - 168ms/step\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000 - 26s/epoch - 172ms/step\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000 - 27s/epoch - 176ms/step\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 1.0000 - 26s/epoch - 170ms/step\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0050 - accuracy: 0.9995 - val_loss: 103.8067 - val_accuracy: 0.6651 - 27s/epoch - 174ms/step\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0028 - val_accuracy: 1.0000 - 27s/epoch - 173ms/step\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 1.0000 - 26s/epoch - 170ms/step\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.0028 - val_accuracy: 1.0000 - 27s/epoch - 172ms/step\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0551 - accuracy: 0.9908 - val_loss: 0.0034 - val_accuracy: 1.0000 - 26s/epoch - 171ms/step\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0271 - accuracy: 0.9963 - val_loss: 0.0040 - val_accuracy: 1.0000 - 26s/epoch - 170ms/step\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0339 - accuracy: 0.9948 - val_loss: 0.0219 - val_accuracy: 0.9889 - 26s/epoch - 170ms/step\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0044 - val_accuracy: 1.0000 - 26s/epoch - 170ms/step\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.0043 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0191 - accuracy: 0.9973 - val_loss: 0.0044 - val_accuracy: 1.0000 - 27s/epoch - 173ms/step\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 1.0000 - 27s/epoch - 173ms/step\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 1.0000 - 27s/epoch - 175ms/step\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 1.0000 - 27s/epoch - 172ms/step\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 1.0000 - 27s/epoch - 177ms/step\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 1.0000 - 27s/epoch - 177ms/step\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "154/154 - 28s - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.0040 - val_accuracy: 1.0000 - 28s/epoch - 179ms/step\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "154/154 - 28s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - 28s/epoch - 183ms/step\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 1.0000 - 27s/epoch - 177ms/step\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 1.0000 - 27s/epoch - 175ms/step\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000 - 26s/epoch - 171ms/step\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000 - 27s/epoch - 174ms/step\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "154/154 - 28s - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 1.0000 - 28s/epoch - 180ms/step\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 1.0000 - 26s/epoch - 170ms/step\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000 - 26s/epoch - 168ms/step\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 1.0000 - 26s/epoch - 167ms/step\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 1.0000 - 26s/epoch - 168ms/step\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000 - 25s/epoch - 166ms/step\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000 - 25s/epoch - 164ms/step\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000 - 25s/epoch - 166ms/step\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - 25s/epoch - 164ms/step\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9993 - 25s/epoch - 165ms/step\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 1.0000 - 26s/epoch - 166ms/step\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0027 - val_accuracy: 1.0000 - 25s/epoch - 165ms/step\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.2023 - accuracy: 0.9855 - val_loss: 673.0264 - val_accuracy: 0.7005 - 26s/epoch - 167ms/step\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0276 - accuracy: 0.9951 - val_loss: 0.0069 - val_accuracy: 1.0000 - 26s/epoch - 169ms/step\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "154/154 - 28s - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0069 - val_accuracy: 1.0000 - 28s/epoch - 181ms/step\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "154/154 - 29s - loss: 0.0226 - accuracy: 0.9990 - val_loss: 0.0071 - val_accuracy: 1.0000 - 29s/epoch - 191ms/step\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "154/154 - 29s - loss: 0.0240 - accuracy: 0.9975 - val_loss: 0.0072 - val_accuracy: 1.0000 - 29s/epoch - 189ms/step\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "154/154 - 28s - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 1.0000 - 28s/epoch - 182ms/step\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0077 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 1.0000 - 26s/epoch - 168ms/step\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 1.0000 - 26s/epoch - 172ms/step\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0074 - accuracy: 0.9997 - val_loss: 0.0066 - val_accuracy: 1.0000 - 26s/epoch - 168ms/step\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 1.0000 - 26s/epoch - 167ms/step\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "154/154 - 27s - loss: 0.0082 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 1.0000 - 27s/epoch - 175ms/step\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 1.0000 - 26s/epoch - 167ms/step\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 1.0000 - 25s/epoch - 165ms/step\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0075 - accuracy: 0.9998 - val_loss: 0.0060 - val_accuracy: 1.0000 - 25s/epoch - 163ms/step\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 1.0000 - 25s/epoch - 162ms/step\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 1.0000 - 25s/epoch - 164ms/step\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 1.0000 - 25s/epoch - 164ms/step\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "154/154 - 26s - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 1.0000 - 26s/epoch - 167ms/step\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0059 - accuracy: 0.9999 - val_loss: 0.0052 - val_accuracy: 1.0000 - 25s/epoch - 165ms/step\n",
      "Epoch 78/80\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - 25s/epoch - 165ms/step\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000 - 25s/epoch - 165ms/step\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "154/154 - 25s - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.0047 - val_accuracy: 1.0000 - 25s/epoch - 164ms/step\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo con nuestro Data Generator\n",
    "hist = model.fit(\n",
    "    # Utiliza las imÃ¡genes generadas por el Train Generator\n",
    "    trainGenerator,\n",
    "    # Utilizar los callbacks que creamos\n",
    "    callbacks = [checkpoint],\n",
    "    # Entrenamos por 80 Ã©pocas\n",
    "    epochs = 80,\n",
    "    # Para validaciÃ³n utilizamos las imÃ¡genes generadas por el Validation Generator\n",
    "    validation_data = validationGenerator,\n",
    "    verbose = 2,\n",
    "    # Mezclar los datos\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EvaluaciÃ³n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history[\"accuracy\"], label = \"Train\")\n",
    "plt.plot(hist.history[\"val_accuracy\"], label = \"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 32ms/step - loss: 0.0047 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004724135622382164, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "postModel = load_model(r\"visionArtificial2023-09-26.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0356 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.035635992884635925, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postModel.evaluate(testGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionArtificial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
